{
    "Data_Transformation_Documentation.ipynb": "{\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# Data analysis before Data Transformation\\n\",\n    \"Data visualization has provided the following information about the unprocessed dataset:\\n\",\n    \"1. When analysis of correlation between age and diabetes is made, there a small fall of cases in between the middle 60s and 70s. Afterwards, an abrupt jump is observed at around 80.\\n\",\n    \"\\n\",\n    \"2. The cases of diabetes in males and females differs very little.\\n\",\n    \"\\n\",\n    \"3. The mean and median do not differ majorly, leading to an almost symmetrical dataset. \\n\",\n    \"\\n\",\n    \"4. The quartiles show an expected variation in attributes.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"vscode\": {\n     \"languageId\": \"plaintext\"\n    }\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"import pandas as pd\\n\",\n    \"import matplotlib.pyplot as plt\\n\",\n    \"import seaborn as sns\\n\",\n    \"\\n\",\n    \"# For term documentation, please visit the Wiki on GitLab: Statistical Term Documentation #\\n\",\n    \"\\n\",\n    \"df = pd.read_csv('smotted_dataset.csv')\\n\",\n    \"\\n\",\n    \"#Show ratio through chart\\n\",\n    \"#sns.countplot(x='diabetes', data=df)\\n\",\n    \"\\n\",\n    \"# Age Distribution\\n\",\n    \"sns.histplot(data=df, x='age', hue='diabetes', multiple='stack')\\n\",\n    \"\\n\",\n    \"# Blood Glucose Levels Distribution\\n\",\n    \"#sns.histplot(data=df, x='current_blood_glucose_level', hue='diabetes', multiple='stack')\\n\",\n    \"\\n\",\n    \"#HbA1c_level\\n\",\n    \"#sns.histplot(data=df, x='average_blood_glucose_level', hue='diabetes', multiple='stack')\\n\",\n    \"\\n\",\n    \"# Weight Distribution\\n\",\n    \"# Plot KDE for BMI with diabetes status\\n\",\n    \"#sns.kdeplot(data=df, x='bmi', hue='diabetes', fill=True)\\n\",\n    \"\\n\",\n    \"numerical_df = df.select_dtypes(include=['float64', 'int64']).drop(columns=['hypertension', 'heart_disease', 'diabetes'])\\n\",\n    \"# Mean and Median\\n\",\n    \"print(\\\"Median:\\\", numerical_df.median(), \\\"\\\\n\\\")\\n\",\n    \"print(\\\"Mean:\\\", numerical_df.mean(), \\\"\\\\n\\\")\\n\",\n    \"\\n\",\n    \"# Standard Deviation\\n\",\n    \"print(\\\"Standard Deviation:\\\", numerical_df.std())\\n\",\n    \"\\n\",\n    \"# The values at the quartile divisions\\n\",\n    \"print(numerical_df.quantile(q=[0.25, 0.5, 0.75], axis=0, numeric_only=True))\\n\",\n    \"\\n\",\n    \"plt.show()\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# Removal of Incomplete Examples in Dataset\\n\",\n    \"With the utilization of Pandas, any incomplete examples present in our dataset were removed. Afterwards, we have analyzed the data to ensure that all of our labels are direct labels and not proxy labels.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"vscode\": {\n     \"languageId\": \"plaintext\"\n    }\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"import pandas as pd\\n\",\n    \"\\n\",\n    \"df = pd.read_csv('cleaned_dataset.csv')\\n\",\n    \"df.dropna()\\n\",\n    \"df = df.drop_duplicates()\\n\",\n    \"df.reset_index(drop=True, inplace=True)\\n\",\n    \"\\n\",\n    \"df.to_csv('cleaned_dataset.csv', index=False)\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"vscode\": {\n     \"languageId\": \"plaintext\"\n    }\n   },\n   \"source\": [\n    \"# Balancing Dataset\\n\",\n    \"Furthermore, the next step was reaching a dataset which was as balanced as possible. Initially, the dataset had a ratio of approximately 10:1 (10 non-diabetic individuals for a single diabetic patient).\\n\",\n    \"\\n\",\n    \"The following steps were performed:\\n\",\n    \"1. The majority class was downsampled by a factor of 5 (20%). Although the downsampling could have been up to a factor of 10, this would lead to extreme data loss.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"vscode\": {\n     \"languageId\": \"plaintext\"\n    }\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"from imblearn.under_sampling import RandomUnderSampler\\n\",\n    \"import pandas as pd\\n\",\n    \"\\n\",\n    \"df = pd.read_csv('cleaned_dataset.csv')\\n\",\n    \"\\n\",\n    \"X = df.drop('diabetes', axis=1)\\n\",\n    \"y = df['diabetes']\\n\",\n    \"\\n\",\n    \"# Undersampling the majority class\\n\",\n    \"# Sampling Strategy allows to remove a certain percentage of the majority in this case. Currently, we undersample by a factor of 5.#\\n\",\n    \"# Ratio is 5:1 for non-diabetics \\n\",\n    \"rus = RandomUnderSampler(random_state=42, sampling_strategy = 0.2)\\n\",\n    \"X_res, y_res = rus.fit_resample(X, y)\\n\",\n    \"\\n\",\n    \"# Ratio after undersampling\\n\",\n    \"ratio = 42410 / 8482\\n\",\n    \"#print(X_res.value_counts(), y_res.value_counts(), f\\\"Ratio: {ratio}\\\")\\n\",\n    \"df_resampled = pd.concat([X_res, y_res], axis=1)\\n\",\n    \"df_resampled['age'] = df_resampled['age'].astype(int)\\n\",\n    \"df_resampled.to_csv('downsampled_dataset.csv', index=False) # Creates a different file with removed majority #\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"2. The minority class was oversampled utilizing the Synthetic Minority Over-sampling Technique for Nominal and Continuous. (SMOTENC) method. SMOTENC is required, as the dataset contains both categorical and numerical data. Although overfitting is still a problem to be considered, as new data isn't created but fabricated from pre-existing data, it reduces the chances of overfitting in comparison to Random Oversampling.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"vscode\": {\n     \"languageId\": \"plaintext\"\n    }\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"from imblearn.over_sampling import SMOTENC\\n\",\n    \"import pandas as pd\\n\",\n    \"\\n\",\n    \"# Read the data\\n\",\n    \"df = pd.read_csv('downsampled_dataset.csv')\\n\",\n    \"X = df.drop('diabetes', axis=1)\\n\",\n    \"y = df['diabetes']\\n\",\n    \"\\n\",\n    \"# Convert categorical variables to numeric codes before SMOTE\\n\",\n    \"valid_smoking_history = ['never', 'former', 'current', 'No Info']\\n\",\n    \"X['smoking_history'] = pd.Categorical(X['smoking_history'], \\n\",\n    \"                                    categories=valid_smoking_history,\\n\",\n    \"                                    ordered=False)\\n\",\n    \"X['smoking_history'] = X['smoking_history'].cat.codes\\n\",\n    \"\\n\",\n    \"# Get the indices of categorical features\\n\",\n    \"categorical_features_indices = [X.columns.get_loc(col) for col in ['gender', 'smoking_history']]\\n\",\n    \"\\n\",\n    \"# Apply SMOTE\\n\",\n    \"smote = SMOTENC(random_state=42, \\n\",\n    \"                sampling_strategy=0.5, \\n\",\n    \"                k_neighbors=5, \\n\",\n    \"                categorical_features=categorical_features_indices)\\n\",\n    \"X_res, y_res = smote.fit_resample(X, y)\\n\",\n    \"\\n\",\n    \"# Convert smoking_history back to categories\\n\",\n    \"X_res['smoking_history'] = pd.Categorical.from_codes(\\n\",\n    \"    X_res['smoking_history'].astype('int'),\\n\",\n    \"    categories=valid_smoking_history\\n\",\n    \")\\n\",\n    \"\\n\",\n    \"# Round numerical columns to match desired format\\n\",\n    \"# Assuming the columns are in this order: age, hypertension, heart_disease, bmi, HbA1c_level, blood_glucose_level\\n\",\n    \"X_res['age'] = X_res['age'].round().astype(int)\\n\",\n    \"X_res['bmi'] = X_res['bmi'].round(2)\\n\",\n    \"X_res['average_blood_glucose_level'] = X_res['average_blood_glucose_level'].round(1)\\n\",\n    \"X_res['current_blood_glucose_level'] = X_res['current_blood_glucose_level'].round().astype(int)\\n\",\n    \"# hypertension and heart_disease should already be 0 or 1\\n\",\n    \"\\n\",\n    \"# Create the resampled dataset\\n\",\n    \"df_resampled = pd.concat([X_res, y_res], axis=1)\\n\",\n    \"\\n\",\n    \"# Save with correct formatting\\n\",\n    \"df_resampled.to_csv('smotted_dataset.csv', index=False, float_format='%.2f')\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# Splitting Dataset\\n\",\n    \"The dataset was split into a Training Set, Validation Set and Test Set:\\n\",\n    \"- Training Set: 70%\\n\",\n    \"- Validation Set: 15%\\n\",\n    \"- Test Set: 15%\\n\",\n    \"\\n\",\n    \"The initial splitting of the dataset leads to a 1:3 imbalance for diabetics. Variations will be tested on the models being trained and documented in the future. \"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"vscode\": {\n     \"languageId\": \"plaintext\"\n    }\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"from sklearn.model_selection import train_test_split\\n\",\n    \"import pandas as pd\\n\",\n    \"\\n\",\n    \"df = pd.read_csv('smotted_dataset.csv')\\n\",\n    \"X = df.drop('diabetes', axis=1)\\n\",\n    \"y = df['diabetes']\\n\",\n    \"\\n\",\n    \"# First split\\n\",\n    \"X_train, X_test, y_train, y_test = train_test_split(X,y , \\n\",\n    \"                                   random_state=104,  \\n\",\n    \"                                   test_size=0.3,  \\n\",\n    \"                                   shuffle=True)\\n\",\n    \"\\n\",\n    \"df_train = pd.concat([X_train, y_train], axis=1)\\n\",\n    \"df_test = pd.concat([X_test, y_test], axis = 1)\\n\",\n    \"\\n\",\n    \"df_train.to_csv('train_dataset.csv', index = False, float_format='%.2f')\\n\",\n    \"\\n\",\n    \"# Second split\\n\",\n    \"X = df_test.drop('diabetes', axis=1)\\n\",\n    \"y = df_test['diabetes']\\n\",\n    \"X_validation, X_test, y_validation, y_test = train_test_split(X,y , \\n\",\n    \"                                            random_state=104,  \\n\",\n    \"                                            test_size=0.5,  \\n\",\n    \"                                            shuffle=True)\\n\",\n    \"\\n\",\n    \"df_test = pd.concat([X_test, y_test], axis = 1)\\n\",\n    \"df_validation = pd.concat([X_validation, y_validation], axis = 1)\\n\",\n    \"\\n\",\n    \"df_test.to_csv('test_dataset.csv', index= False, float_format='%.2f')\\n\",\n    \"df_validation.to_csv('validation_dataset.csv', index= False, float_format='%.2f')\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# Transforming Categorical Data into Floating Point using Hot-End Encoding\\n\",\n    \"As models can only train with floating point values, categorical data (data which is string, or numbers which can not be cateorized as numerical data, such as postal codes) must be transformed into numerical data. As each categorical value of our dataset does not contain more than 4 different categories, we have opted for Hot-End Encoding.\\n\",\n    \"\\n\",\n    \"Hod-End Encoding will split the categorical data into multiple columns. For example, when the column \\\"Gender\\\" is Hot-End Encoded, it will end up having Gender_Female and Gender_Male. 1 will represent the presence, 0 the absence, in order to avoid biases.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"vscode\": {\n     \"languageId\": \"plaintext\"\n    }\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"import pandas as pd\\n\",\n    \"from sklearn.preprocessing import OneHotEncoder\\n\",\n    \"\\n\",\n    \"# Read the dataset\\n\",\n    \"df = pd.read_csv('Data Transformation/linear_scaled_dataset.csv')\\n\",\n    \"\\n\",\n    \"# Extract categorical columns from the dataframe\\n\",\n    \"categorical_columns = ['gender', 'hypertension', 'heart_disease', 'smoking_history', 'diabetes']\\n\",\n    \"\\n\",\n    \"# Initialize OneHotEncoder (dropping the first category to avoid redundant columns)\\n\",\n    \"encoder = OneHotEncoder(sparse_output=False, drop='first')\\n\",\n    \"\\n\",\n    \"# Apply one-hot encoding to the categorical columns\\n\",\n    \"one_hot_encoded = encoder.fit_transform(df[categorical_columns])\\n\",\n    \"\\n\",\n    \"# Create a DataFrame with the one-hot encoded columns\\n\",\n    \"one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(categorical_columns))\\n\",\n    \"\\n\",\n    \"# Create a DataFrame for the original numerical columns\\n\",\n    \"numerical_columns = ['age', 'bmi', 'average_blood_glucose_level', 'current_blood_glucose_level']\\n\",\n    \"numerical_df = df[numerical_columns]\\n\",\n    \"\\n\",\n    \"# Concatenate the one-hot encoded dataframe with the original numerical dataframe\\n\",\n    \"df_encoded = pd.concat([numerical_df, one_hot_df], axis=1)\\n\",\n    \"\\n\",\n    \"# Save the encoded DataFrame to a CSV file\\n\",\n    \"df_encoded.to_csv('cat_to_num.csv', index=False)\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# Normalization\\n\",\n    \"Data visualization after the balancing technique SMOTE-NC has been applied shows the following:\\n\",\n    \"1. When analysis of correlation between age and diabetes is made, a zig-zag pattern is observed and a sudden jump in registered cases happens at 75-80, to about double the amount of the other highest reigstered number of cases. To combat prediction bias, both will be addressed.\\n\",\n    \"\\n\",\n    \"2. The cases of diabetes in males and females differs slightly.\\n\",\n    \"\\n\",\n    \"3. The mean and median still do not differ majorly, although the SMOTE-NC balancing has added some variation. The standard deviation shows the biggest change in the blood glucose levels, which have spiked from 40.90 to 52.55.\\n\",\n    \"\\n\",\n    \"4. The quartiles show an expected variation in attributes, although has a higher variation in comparison to the original dataset.\\n\",\n    \"\\n\",\n    \"## Linear Scaling\\n\",\n    \"Given that the dataset does not seem to be in a normal distribution, required for Z-Score standardization, nor have a consistent relation of power law, we have opted for linear scaling: the lower and upper values should, in theory, not change over time. Additionally, the dataset contains few to no outliers. \\n\",\n    \"\\n\",\n    \"The only problem is the fact that the features are not all uniformly distributed across their ranges, are some are more right skewed. Age would be an example.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"vscode\": {\n     \"languageId\": \"plaintext\"\n    }\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"import pandas as pd\\n\",\n    \"from sklearn.preprocessing import MinMaxScaler\\n\",\n    \"\\n\",\n    \"df = pd.read_csv('smotted_dataset.csv')\\n\",\n    \"\\n\",\n    \"scaler = MinMaxScaler()\\n\",\n    \"df[['age', 'bmi', 'average_blood_glucose_level', 'current_blood_glucose_level']] = scaler.fit_transform(df[['age', 'bmi', 'average_blood_glucose_level', 'current_blood_glucose_level']])\\n\",\n    \"\\n\",\n    \"df.to_csv('linear_scaled_dataset.csv', index=False)\"\n   ]\n  }\n ],\n \"metadata\": {\n  \"language_info\": {\n   \"name\": \"python\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 2\n}\n",
    "requirements.txt": "streamlit\npandas\nnumpy\npydeck\nmatplotlib\nseaborn\nimblearn\nsklearn\nscikit-learn\nmatplotlib\nscikit-learn\nmatplotlib\ntime\njoblib\nrasa",
    "README.md": "Vaidasigan Name2-Iulia 22301079\n\nElbermawy Name1 12306597\n\nDiaPredictor\n\n[GitHub Repository](https://github.com/FaresM7/DiaPredictor)\n\n[GitHub Wiki](https://github.com/FaresM7/DiaPredictor/-/wikis/home)\n\n## Project Description\n\nDiaPredictor\n\n## Installation\n\nTo set up the project on another machine, make sure you have the following dependencies and versions installed:\n\n- **Python**: version X.X\n- **scikit-learn**: version X.X.X\n- **Streamlit**: version X.X.X\n- **Rasa**: version X.X.X\n- [Other dependencies...]\n\n### Installation Steps\n1. Clone the repository:\n   ~~~bash\n   git clone https://gitlab.com/username/GitHub.git\n\n",
    ".gitignore": "...",
    "🩺_Intro.py": "import streamlit as st\n\n# Page configuration\nst.set_page_config(page_title=\"Diabetes Prediction Web App\", page_icon=\"🩺\", layout=\"centered\")\n\n# Main title\nst.markdown(\"# Welcome to the Diabetes Prediction Web App\")\nst.write(\n    \"\"\"\n    This web application is designed to provide insights into diabetes prediction by analyzing key health metrics\n    and exploring the impact of data transformations on predictive modeling.\n    \"\"\"\n)\n\n# Purpose of the Web App\nst.markdown(\"### Purpose\")\nst.write(\n    \"\"\"\n    The main goal of this app is to:\n    \n    - Explore and visualize the dataset used for diabetes prediction.\n    - Demonstrate how data preprocessing impacts model performance.\n    - Compare different regression models and evaluate their accuracy in predicting diabetes probabilities.\n    - Provide an interactive and intuitive way to understand the importance of data transformations in machine learning.\n    \"\"\"\n)\n\n# Overview of Features\nst.markdown(\"### What This Web App Includes\")\nst.write(\n    \"\"\"\n    - **Dataset Overview**:\n      - A detailed look at the original and modified datasets, including their features, transformations, and key characteristics.\n    - **Data Visualization**:\n      - Interactive visualizations to uncover patterns and relationships in the dataset.\n    - **Model Training**:\n      - A comparison of regression models (Linear Regression and Decision Tree) for predicting diabetes probabilities.\n    - **Performance Metrics**:\n      - Insight into model performance through metrics such as Mean Squared Error (MSE) and R² Score.\n    \"\"\"\n)\n\n# Call to Action\nst.markdown(\"### Navigate to Other Pages\")\nst.write(\n    \"\"\"\n    Use the sidebar to explore each page:\n    \n    - **Dataset Overview**: Learn about the datasets and their transformations.\n    - **Data Visualization**: Dive into visual patterns within the data.\n    - **Model Training**: Understand how models are trained and compare their performance.\n    \"\"\"\n)\n\n\n",
    "dir_to_json.py": "import os\nimport json\nimport fnmatch\nimport mimetypes\n\n# Define the extensions that require partial content\nPARTIAL_READ_EXTENSIONS = {'.csv', '.jsonl', '.txt', '.log'}  # Add more extensions as needed\n\n# Initialize explicit filenames to include as \"...\" in JSON\nEXPLICIT_IGNORE_FILES = {\n    'LICENSE', 'CHANGELOG.md', '.dockerignore', '.gitignore',\n    '.ignore', 'a_personas.md', 'b_use_cases.md', 'c_outlier_handling.md',\n    'd_chatbot_use_case.md', 'e_sample_dialogs.md', 'f_dialog_flow.md'\n}  # Default filenames\n\ndef parse_ignore_file(ignore_file_path):\n    \"\"\"\n    Parses an ignore file and returns a set of filenames or patterns to ignore.\n    Ignores empty lines and comments starting with '#'.\n    \"\"\"\n    ignored_patterns = set()\n    try:\n        with open(ignore_file_path, 'r', encoding='utf-8') as file:\n            for line in file:\n                line = line.strip()\n                if line and not line.startswith('#'):\n                    # Normalize the pattern\n                    normalized_pattern = os.path.normpath(line)\n                    ignored_patterns.add(normalized_pattern)\n    except FileNotFoundError:\n        pass  # If ignore file does not exist, proceed with default ignore list\n    return ignored_patterns\n\n# Optionally, extend the ignore list by parsing an external .ignore file\nIGNORE_FILE_PATH = os.path.join('.', '.ignore')  # Adjust the path if necessary\nIGNORE_PATTERNS = parse_ignore_file(IGNORE_FILE_PATH)\n\ndef read_partial_file(file_path, first_n=10, last_m=5):\n    \"\"\"\n    Reads the first ~first_n~ lines and the last ~last_m~ lines of a file.\n    Inserts '...' if the file has more than ~first_n + last_m~ lines.\n    \"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as file:\n            first_lines = []\n            last_lines = []\n            for line in file:\n                if len(first_lines) < first_n:\n                    first_lines.append(line.rstrip('\\n').replace('~', '~'))\n                last_lines.append(line.rstrip('\\n').replace('~', '~'))\n                if len(last_lines) > last_m:\n                    last_lines.pop(0)\n\n            total_lines = len(first_lines) + len(last_lines)\n            # Estimate if there are more lines than first_n + last_m\n            # This is a simplistic check; for large files, consider a different approach\n            with open(file_path, 'r', encoding='utf-8') as f:\n                total = sum(1 for _ in f)\n            if total > first_n + last_m:\n                return '\\n'.join(first_lines) + '\\n...\\n' + '\\n'.join(last_lines)\n            else:\n                return '\\n'.join(first_lines + last_lines)\n    except Exception:\n        return \"...\"\n\ndef read_file(file_path):\n    \"\"\"\n    Reads a file and returns its content appropriately, handling different file types.\n    For specified extensions, it returns a partial content with '...'.\n    For image files, it returns '...'.\n    For other text files, it returns the full content with backticks replaced by tildes.\n    \"\"\"\n    if os.path.basename(file_path) in EXPLICIT_IGNORE_FILES:\n        return \"...\"\n    try:\n        mime_type, _ = mimetypes.guess_type(file_path)\n        if mime_type and mime_type.startswith('image'):\n            return \"...\"\n\n        _, ext = os.path.splitext(file_path)\n        if ext.lower() in PARTIAL_READ_EXTENSIONS:\n            return read_partial_file(file_path)\n\n        with open(file_path, 'r', encoding='utf-8') as file:\n            content = file.read()\n            return content.replace('~', '~')\n    except (UnicodeDecodeError, FileNotFoundError):\n        return \"...\"\n\ndef is_ignored(file_path, ignore_patterns):\n    \"\"\"\n    Checks if a file path matches any of the ignore patterns.\n    Handles directory patterns by appending a '/' for accurate matching.\n    \"\"\"\n    normalized_path = os.path.normpath(file_path)\n    for pattern in ignore_patterns:\n        normalized_pattern = os.path.normpath(pattern)\n        if pattern.endswith('/'):\n            # Directory pattern\n            if fnmatch.fnmatch(normalized_path + '/', normalized_pattern):\n                return True\n        else:\n            if fnmatch.fnmatch(normalized_path, normalized_pattern):\n                return True\n    return False\n\ndef is_in_submodule(file_path, submodule_paths):\n    \"\"\"\n    Checks if a file path is within any of the submodule paths.\n    \"\"\"\n    normalized_path = os.path.normpath(file_path)\n    for submodule_path in submodule_paths:\n        normalized_submodule = os.path.normpath(submodule_path)\n        if normalized_path.startswith(normalized_submodule + os.sep):\n            return True\n    return False\n\ndef dir_to_json(directory, submodules, ignore_submodules=False):\n    \"\"\"\n    Converts a directory structure into a JSON object, optionally ignoring submodules.\n    \"\"\"\n    result = {}\n    submodule_paths = [os.path.normpath(os.path.join(directory, submodule['path'])) for submodule in submodules]\n\n    # Initialize ignore patterns\n    global_ignore_patterns = set(IGNORE_PATTERNS)\n    global_gitignore_patterns = set()\n\n    for root, dirs, files in os.walk(directory):\n        # Skip .git directories\n        if '.git' in dirs:\n            dirs.remove('.git')\n\n        # Compute the relative path from the base directory\n        relative_root = os.path.relpath(root, directory)\n        if relative_root == \".\":\n            relative_root = \"\"\n\n        # Handle submodule ignoring\n        if ignore_submodules and is_in_submodule(root, submodule_paths):\n            # Optionally, skip entire submodule directories\n            dirs[:] = []  # Prevent walking into subdirectories\n            continue\n\n        # Parse .ignore and .gitignore files in the current directory\n        ignore_file_path = os.path.join(root, '.ignore')\n        gitignore_file_path = os.path.join(root, '.gitignore')\n\n        local_ignore_patterns = parse_ignore_file(ignore_file_path)\n        local_gitignore_patterns = parse_ignore_file(gitignore_file_path)\n\n        # Update global ignore patterns\n        global_ignore_patterns.update(local_ignore_patterns)\n        global_gitignore_patterns.update(local_gitignore_patterns)\n\n        # Remove ignored directories from traversal\n        dirs_to_remove = []\n        for d in dirs:\n            dir_relative_path = os.path.normpath(os.path.join(relative_root, d))\n            if is_ignored(dir_relative_path, global_ignore_patterns):\n                dirs_to_remove.append(d)\n        for d in dirs_to_remove:\n            dirs.remove(d)\n\n        # Navigate to the correct location in the result dictionary\n        sub_result = result\n        if relative_root:\n            for part in relative_root.split(os.sep):\n                sub_result = sub_result.setdefault(part, {})\n\n        for file in files:\n            file_path = os.path.join(root, file)\n            relative_file_path = os.path.relpath(file_path, directory)\n            relative_file_path = os.path.normpath(relative_file_path)\n\n            # Check if file should be completely ignored\n            if is_ignored(relative_file_path, global_ignore_patterns):\n                continue  # Do not include in JSON at all\n\n            # Check if file should be included as \"...\" (from .gitignore or explicit ignore)\n            if is_ignored(relative_file_path, global_gitignore_patterns) or file in EXPLICIT_IGNORE_FILES:\n                sub_result[file] = \"...\"\n                continue\n\n            # Handle submodules\n            if ignore_submodules and is_in_submodule(file_path, submodule_paths) and 'README' not in file:\n                continue\n\n            # Read and assign file content\n            file_content = read_file(file_path)\n            sub_result[file] = file_content\n\n    return result\n\ndef load_submodules(gitmodules_path):\n    \"\"\"\n    Loads submodules from the .gitmodules file.\n    \"\"\"\n    submodules = []\n    try:\n        with open(gitmodules_path, 'r', encoding='utf-8') as gitmodules_file:\n            current_submodule = {}\n            for line in gitmodules_file:\n                line = line.strip()\n                if line.startswith('[submodule'):\n                    if current_submodule:\n                        submodules.append(current_submodule)\n                        current_submodule = {}\n                elif line.startswith('path') and '=' in line:\n                    _, path = line.split('=', 1)\n                    current_submodule['path'] = path.strip()\n            if current_submodule:\n                submodules.append(current_submodule)\n    except FileNotFoundError:\n        pass  # No submodules present\n    return submodules\n\ndef main(directory='.', ignore_submodules=False, output_file='output.json'):\n    \"\"\"\n    Main function to generate the directory structure in JSON format.\n    \"\"\"\n    gitmodules_path = os.path.join(directory, '.gitmodules')\n    submodules = load_submodules(gitmodules_path)\n\n    json_data = dir_to_json(directory, submodules, ignore_submodules)\n    json_output = os.path.join(directory, output_file)\n\n    try:\n        with open(json_output, 'w', encoding='utf-8') as json_file:\n            json.dump(json_data, json_file, ensure_ascii=False, indent=4)\n        print(f\"JSON data has been written to {json_output}\")\n    except Exception as e:\n        print(f\"Failed to write JSON data to {json_output}: {e}\")\n\nif __name__ == \"__main__\":\n    import argparse\n\n    parser = argparse.ArgumentParser(description=\"Convert directory structure to JSON.\")\n    parser.add_argument(\n        '-d', '--directory',\n        type=str,\n        default='.',\n        help='Directory to convert (default: current directory)'\n    )\n    parser.add_argument(\n        '-i', '--ignore-submodules',\n        action='store_true',\n        help='Ignore submodule directories'\n    )\n    parser.add_argument(\n        '-o', '--output',\n        type=str,\n        default='output.json',\n        help='Output JSON file name (default: output.json)'\n    )\n\n    args = parser.parse_args()\n    main(directory=args.directory, ignore_submodules=args.ignore_submodules, output_file=args.output)\n",
    "Additional_Scripts": {
        "stories.txt": "version: \"3.1\"\n\n# Use Case 1\nstories:\n  - story: Diabetes Prediction Check (Moderate Risk)\n    steps:\n      - action: utter_hello\n      - intent: ask_for_diabetes_check\n      - action: utter_age\n      - intent: provide_age\n...\n      - action: utter_current_glucose\n      - intent: provide_current_glucose\n        entities:\n          - current_glucose: 180\n      - action: action_provide_tips",
        "columns_diabetes_probability.py": "import pandas as pd\nimport numpy as np\n\n# Read the dataset\ndf = pd.read_csv('/home/morningstar/Desktop/assistance-systems-project/Datasets/modified_dataset.csv')\n\n# Drop columns we don't need\ndf.drop(columns=['gender_Male', 'gender_Other', 'smoking_current', 'smoking_history_nan', 'smoking_history_never'], axis=1, inplace=True)\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Remove the diabetes columns from the dataset entirely\ndf = df.drop(columns=['diabetes_1'])\n\n# Create a basic probability score (this is where we combine factors)\n# The numbers by which we multiply are weights\ndf['diabetes'] = (\n    0.1 * df['age'] +  # Age factor\n    0.2 * df['bmi'] +  # BMI factor\n    0.2 * df['average_blood_glucose_level'] +  # Average blood glucose level\n    0.2 * df['current_blood_glucose_level'] +  # Current blood glucose level\n    0.1 * df['hypertension_1'] +  # Hypertension history (1 = has hypertension)\n    0.2 * df['heart_disease_1'] + \n    0.1 * df['smoking_history_former'] \n)\n\n# Add random noise to introduce variability\ndf['diabetes'] += np.random.uniform(0, 0.2, size=len(df))\n\n# Clip the values to ensure they are between 0 and 1\ndf['diabetes'] = df['diabetes'].clip(0, 1)\n\n# Save the modified dataset with the new target variable\ndf.to_csv('/home/morningstar/Desktop/assistance-systems-project/Datasets/modified_with_sick_prob.csv', index=False)\n\nprint(\"Target variable 'probability_of_getting_sick' added and file saved.\")\n",
        "normalizing_inputs.py": "import numpy as np\nfrom sklearn.preprocessing import  MinMaxScaler # For the normalization fo values\n\ndef normalize_inputs(inputs, smoking_history, hypertension, heart_disease):\n    if smoking_history == \"Never\":\n            smoking_history_encoded = 0  \n    elif smoking_history == \"Former\":\n        smoking_history_encoded = 1  \n    else:\n        smoking_history_encoded = 2  \n\n    # Normalize hypertension value: \"Yes\"/\"No\" to 1/0\n    if hypertension == \"Yes\" or hypertension == True:\n        hypertension_normalized = 1  \n    else:\n        hypertension_normalized = 0 \n\n    if heart_disease == \"Yes\" or heart_disease == True:\n        heart_disease_normalized = 1\n    else:\n        heart_disease_normalized = 0\n\n    # Normalizes input values\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    scaler.fit([[0, 10.0, 4.0, 4.0], [100, 50.0, 14.0, 14.0]])  # Min and max values for each feature to be able to utilize the Min-Max Scaler\n    normalized_inputs = scaler.transform(inputs)\n    age, bmi, avg_glucose, current_glucose = normalized_inputs[0]\n\n    smoking_history_normalized = smoking_history_encoded / 2  # Dividing by 2 to scale between 0 and 1\n\n    # Prepare user input as a feature vector\n    features = np.array([\n        [\n            age,\n            bmi,\n            avg_glucose,\n            current_glucose,\n            hypertension_normalized,             # Convert checkbox to binary\n            heart_disease_normalized,            # Convert checkbox to binary\n            smoking_history_normalized   # One-hot encoding for \"Current\"    \n        ]\n    ])\n\n    return features",
        "__pycache__": {
            "normalizing_inputs.cpython-310.pyc": "..."
        }
    },
    "pages": {
        "3_📈_Modified_Dataset_Training.py": "import streamlit as st\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport time\nimport joblib\n\n# Page Configuration\nst.set_page_config(page_title=\"Model Training Comparison\", page_icon=\"📊\")\n\n# Main Title\nst.markdown(\"# Model Training: Linear vs Decision Trees on Modified Dataset\")\n\n\nprogress_text = \"Training in progress. Please wait.\"\nmy_bar = st.progress(0, text=progress_text)\n\nfor percent_complete in range(100):\n    time.sleep(0.01)\n    my_bar.progress(percent_complete + 1, text=progress_text)\ntime.sleep(1)\nmy_bar.empty()\n\n# Information Text\nst.write(\n    \"\"\"This page demonstrates the difference in results between training a\nLinear Regression model and a Decision Tree model using the Modified dataset.\nVisualizations are provided to compare the models' performance and predictions.\"\"\"\n)\n\n@st.cache_data\ndef open_database():\n    data = pd.read_csv('Datasets/modified_dataset.csv')\n    return data\n\n# Read the dataset\ndf = open_database()\n\n# Shuffle the data\ndf = shuffle(df, random_state=42).reset_index(drop=True)\n\n# Separate features and target\nX = df.drop(columns=['diabetes'])\ny = df['diabetes']\n\n# Split: 70% training, 30% temporary set (which will be split into test and validation)\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Split the temporary set into 50% test and 50% validation\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n\n# Train Linear Regression model\nlr_model = LinearRegression()\nlr_model.fit(X_train, y_train)\n\n#Storing it to be used in the 5th page since it is the best resulting model.\njoblib.dump(lr_model, \"Datasets/model.pkl\")\n\n# Make predictions on the validation and test sets for Linear Regression\ny_val_pred_lr = lr_model.predict(X_val)\ny_test_pred_lr = lr_model.predict(X_test)\n\n# Calculate MSE and R² for Linear Regression\nmse_val_lr = mean_squared_error(y_val, y_val_pred_lr)\nr2_val_lr = r2_score(y_val, y_val_pred_lr)\nmse_test_lr = mean_squared_error(y_test, y_test_pred_lr)\nr2_test_lr = r2_score(y_test, y_test_pred_lr)\n\n# Initialize and train Random Forest Regressor\nrf_model = DecisionTreeRegressor()\nrf_model.fit(X_train, y_train)\n\n# Make predictions on validation and test sets\ny_val_pred_tree = rf_model.predict(X_val)\ny_test_pred_tree = rf_model.predict(X_test)\n\n# Calculate MSE and R² for Decision Tree\nmse_val_tree = mean_squared_error(y_val, y_val_pred_tree)\nr2_val_tree = r2_score(y_val, y_val_pred_tree)\nmse_test_tree = mean_squared_error(y_test, y_test_pred_tree)\nr2_test_tree = r2_score(y_test, y_test_pred_tree)\n\nst.write(\" R2: the greater the value, the better the model is predicting.\")\nst.write(\" MSE: the lower the value, the better the model is predicting. \")\n\n# Display results in a table\nst.markdown(\"### Model Performance Summary\")\n\nst.write(\"\"\"\n| Metric                            | Linear Regression | Decision Tree      |\n|-----------------------------------|-------------------|--------------------|\n| **Validation MSE**                | {:.4f}            | {:.4f}             |\n| **Validation R²**                 | {:.4f}            | {:.4f}             |\n| **Test MSE**                      | {:.4f}            | {:.4f}             |\n| **Test R²**                       | {:.4f}            | {:.4f}             |\n\"\"\".format(\n    mse_val_lr, mse_val_tree,\n    r2_val_lr, r2_val_tree,\n    mse_test_lr, mse_test_tree,\n    r2_test_lr, r2_test_tree\n))\n\n# Plotting MSE and R² for both models\nmetrics = ['Validation MSE', 'Test MSE', 'Validation R²', 'Test R²']\nlinear_values = [mse_val_lr, mse_test_lr, r2_val_lr, r2_test_lr]\ntree_values = [mse_val_tree, mse_test_tree, r2_val_tree, r2_test_tree]\n\nfig, axes = plt.subplots(2, 2, figsize=(10, 8))\n\n# Validation MSE\naxes[0, 0].bar(['Linear', 'Tree'], [mse_val_lr, mse_val_tree], color=['blue', 'orange'])\naxes[0, 0].set_title('Validation MSE')\naxes[0, 0].set_ylabel('Mean Squared Error')\n\n# Test MSE\naxes[0, 1].bar(['Linear', 'Tree'], [mse_test_lr, mse_test_tree], color=['blue', 'orange'])\naxes[0, 1].set_title('Test MSE')\naxes[0, 1].set_ylabel('Mean Squared Error')\n\n# Validation R²\naxes[1, 0].bar(['Linear', 'Tree'], [r2_val_lr, r2_val_tree], color=['blue', 'orange'])\naxes[1, 0].set_title('Validation R²')\naxes[1, 0].set_ylabel('R² Score')\n\n# Test R²\naxes[1, 1].bar(['Linear', 'Tree'], [r2_test_lr, r2_test_tree], color=['blue', 'orange'])\naxes[1, 1].set_title('Test R²')\naxes[1, 1].set_ylabel('R² Score')\n\n# Adjust layout\nplt.tight_layout()\n\n# Display the plots in Streamlit\nst.pyplot(fig)",
        "1_🌍_Display_Original_Data.py": "import streamlit as st\nimport pandas as pd\n\n# Page configuration\nst.set_page_config(page_title=\"Dataset Overview\", page_icon=\"📊\")\n\n# Page title and description\nst.markdown(\"# Diabetes Prediction Dataset Overview\")\nst.write(\n    \"\"\"\n    This dataset is designed for predicting diabetes status based on several health indicators and lifestyle factors. Below is an overview of the dataset's features:\n    \n    - **Gender**: Represents the gender of the individual, with values as \"Male\" or \"Female\".\n    - **Age**: The age of the individual, represented as an integer.\n    - **Hypertension**: Indicates high blood pressure presence. It is binary: ~0 = No~, ~1 = Yes~.\n    - **Heart Disease**: Indicates heart disease presence. It is binary: ~0 = No~, ~1 = Yes~.\n    - **Smoking History**: Categorical data that represents smoking status, such as \"never smoked,\" \"used to smoke,\" or \"currently smoking.\"\n    - **BMI (Body Mass Index)**: A measure of body fat based on height and weight, represented by float values.\n    - **Average Blood Glucose Level**: The average blood glucose level over the past 2-3 months, usually used to monitor diabetes. Represented as floats, typically between ~4.0~ to ~14.0~.\n    - **Blood Glucose Level**: The current blood glucose level, typically represented by float values starting from ~80 mg/dL~ and above.\n    - **Diabetes**: Indicates if the individual has diabetes, where ~0 = No~ and ~1 = Yes~.\n    \"\"\"\n)\n\n@st.cache_data\ndef open_database():\n    data = pd.read_csv('Datasets/original_dataset.csv')\n    return data\n\n# Load the dataset\ndf = open_database()\n\n# Display the dataset\nst.markdown(\"## Dataset Sample\")\nst.write(\"Here is a preview of the dataset used for the diabetes prediction task:\")\nst.write(df.head())\n\n# Display dataset information\nst.markdown(\"## Dataset Details\")\nst.write(\"The dataset contains the following columns and data types:\")\nst.write(df.describe())\n",
        "4_📊_Original_Dataset_Training_And_Plotting.py": "import streamlit as st\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport time\n\n# Page Configuration\nst.set_page_config(page_title=\"Model Training Comparison\", page_icon=\"📊\")\n\n# Main Title\nst.markdown(\"# Model Training: Linear vs Decision Trees on Original Dataset\")\nprogress_text = \"Training in progress. Please wait.\"\nmy_bar = st.progress(0, text=progress_text)\n\nfor percent_complete in range(100):\n    time.sleep(0.01)\n    my_bar.progress(percent_complete + 1, text=progress_text)\ntime.sleep(1)\nmy_bar.empty()\n\n\n\n# Information Text\nst.write(\n    \"\"\"This page demonstrates the difference in results between training a\nLinear Regression model and a Decision Tree model using the original dataset.\nVisualizations are provided to compare the models' performance and predictions.\"\"\"\n)\n\n@st.cache_data\ndef open_database():\n    data = pd.read_csv('Datasets/original_dataset.csv')\n    return data\n\n# Read the dataset\ndf = open_database()\n\n# Shuffle the data\ndf = shuffle(df, random_state=42).reset_index(drop=True)\n\n# Separate features and target\nX = df.drop(columns=['diabetes_1'])\ny = df['diabetes_1']\n\n# Split: 70% training, 30% temporary set (which will be split into test and validation)\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Split the temporary set into 50% test and 50% validation\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n\n# Train Linear Regression model\nlr_model = LinearRegression()\nlr_model.fit(X_train, y_train)\n\n# Make predictions on the validation and test sets for Linear Regression\ny_val_pred_lr = lr_model.predict(X_val)\ny_test_pred_lr = lr_model.predict(X_test)\n\n# Calculate MSE and R² for Linear Regression\nmse_val_lr = mean_squared_error(y_val, y_val_pred_lr)\nr2_val_lr = r2_score(y_val, y_val_pred_lr)\nmse_test_lr = mean_squared_error(y_test, y_test_pred_lr)\nr2_test_lr = r2_score(y_test, y_test_pred_lr)\n\n# Initialize and train Random Forest Regressor\nrf_model = DecisionTreeRegressor()\nrf_model.fit(X_train, y_train)\n\n# Make predictions on validation and test sets\ny_val_pred_tree = rf_model.predict(X_val)\ny_test_pred_tree = rf_model.predict(X_test)\n\n# Calculate MSE and R² for Decision Tree\nmse_val_tree = mean_squared_error(y_val, y_val_pred_tree)\nr2_val_tree = r2_score(y_val, y_val_pred_tree)\nmse_test_tree = mean_squared_error(y_test, y_test_pred_tree)\nr2_test_tree = r2_score(y_test, y_test_pred_tree)\n\nst.write(\" R2: the greater the value, the better the model is predicting.\")\nst.write(\" MSE: the lower the value, the better the model is predicting. \")\n\n# Display results in a table\nst.markdown(\"### Model Performance Summary\")\n\nst.write(\"\"\"\n| Metric                            | Linear Regression | Decision Tree      |\n|-----------------------------------|-------------------|--------------------|\n| **Validation MSE**                | {:.4f}            | {:.4f}             |\n| **Validation R²**                 | {:.4f}            | {:.4f}             |\n| **Test MSE**                      | {:.4f}            | {:.4f}             |\n| **Test R²**                       | {:.4f}            | {:.4f}             |\n\"\"\".format(\n    mse_val_lr, mse_val_tree,\n    r2_val_lr, r2_val_tree,\n    mse_test_lr, mse_test_tree,\n    r2_test_lr, r2_test_tree\n))\n\n# Plotting MSE and R² for both models\nmetrics = ['Validation MSE', 'Test MSE', 'Validation R²', 'Test R²']\nlinear_values = [mse_val_lr, mse_test_lr, r2_val_lr, r2_test_lr]\ntree_values = [mse_val_tree, mse_test_tree, r2_val_tree, r2_test_tree]\n\nfig, axes = plt.subplots(2, 2, figsize=(10, 8))\n\n# Validation MSE\naxes[0, 0].bar(['Linear', 'Tree'], [mse_val_lr, mse_val_tree], color=['blue', 'orange'])\naxes[0, 0].set_title('Validation MSE')\naxes[0, 0].set_ylabel('Mean Squared Error')\n\n# Test MSE\naxes[0, 1].bar(['Linear', 'Tree'], [mse_test_lr, mse_test_tree], color=['blue', 'orange'])\naxes[0, 1].set_title('Test MSE')\naxes[0, 1].set_ylabel('Mean Squared Error')\n\n# Validation R²\naxes[1, 0].bar(['Linear', 'Tree'], [r2_val_lr, r2_val_tree], color=['blue', 'orange'])\naxes[1, 0].set_title('Validation R²')\naxes[1, 0].set_ylabel('R² Score')\n\n# Test R²\naxes[1, 1].bar(['Linear', 'Tree'], [r2_test_lr, r2_test_tree], color=['blue', 'orange'])\naxes[1, 1].set_title('Test R²')\naxes[1, 1].set_ylabel('R² Score')\n\n# Adjust layout\nplt.tight_layout()\n\n# Display the plots in Streamlit\nst.pyplot(fig)",
        "6_🤖_Chatbot.py": "import streamlit as st\nimport rasa",
        "5_🔍_Diabetes_prediction.py": "import streamlit as st\nimport pandas as pd\nimport numpy as np\nimport joblib  # For loading the saved model\nfrom Additional_Scripts import normalizing_inputs\n\n# Page configuration\nst.set_page_config(page_title=\"Diabetes Prediction\", page_icon=\"🔍\")\n\n# Page title and description\nst.markdown(\"# Diabetes Risk Prediction\")\nst.write(\n    \"\"\"\n    Enter your health and lifestyle details below to calculate your risk of having diabetes.\n    This tool uses a machine learning model to provide predictions based on the entered data.\n    \"\"\"\n)\n# Load the trained model\n@st.cache_resource\ndef load_model():\n    return joblib.load(\"Datasets/model.pkl\")\n\n\n# Input Widgets\nage = st.slider(\"Age\", min_value=0, max_value=100, value=30, step=1)\nhypertension = st.checkbox(\"Do you have hypertension?\", value=False)\nheart_disease = st.checkbox(\"Do you have heart disease?\", value=False)\nbmi = st.number_input(\"BMI (Body Mass Index)\", min_value=10.0, max_value=50.0, value=25.0, step=0.1)\navg_glucose = st.number_input(\"Average Blood Glucose Level (mmol/L)\", min_value=4.0, max_value=14.0, value=5.5, step=0.1)\ncurrent_glucose = st.number_input(\"Current Blood Glucose Level (mmol/L)\", min_value=4.0, max_value=14.0, value=5.5, step=0.1)\n# Dropdown for Smoking History\nsmoking_history = st.selectbox(\n    \"Smoking History\",\n    options=[\"Never\", \"Former\", \"Current\"],\n    index=0\n)\n\n# Normalizes input values\ninputs = [[age, bmi, avg_glucose, current_glucose]]\n\n# Prepare user input as a feature vector\nfeature_vector = normalizing_inputs.normalize_inputs(inputs, smoking_history, hypertension, heart_disease)\n\n\n# Button to trigger prediction\nif st.button(\"Predict Diabetes Risk\"):\n    # Load your trained model (replace 'model.pkl' with your model's filename)\n    try:\n        model = load_model()\n        prediction = model.predict(feature_vector)[0]  # Predict using the model\n        st.success(f\"Predicted Diabetes Probability: {prediction:.2f}\")\n\n        # Bar to show severity of prediction \n        progress_percentage = int(prediction * 100)\n        color = \"background-color: red;\" if progress_percentage > 50 else \"background-color: green;\"\n\n        # Display the progress bar with percentage value\n        st.markdown(\n            f\"\"\"\n            <div style=\"width: 100%; height: 30px; border-radius: 5px; {color} width: {progress_percentage}%;\"></div>\n            <span style=\"color: black; font-weight: bold; position: absolute; width: 100%; text-align: center; line-height: 30px;\">\n                {progress_percentage}%\n            </span>\n            \"\"\", \n            unsafe_allow_html=True\n        )\n\n\n        if prediction > 0.5:\n            st.warning(\"You might be at risk for diabetes. Consider consulting a healthcare professional.\")\n        else:\n            st.info(\"You have a low risk of diabetes. Keep maintaining a healthy lifestyle!\")\n\n    except FileNotFoundError:\n        st.error(\"Model file not found. Please ensure the model file is in the correct location.\")\n\n",
        "2_Display_Modified_Data.py": "import streamlit as st\nimport pandas as pd\n\n# Page configuration\nst.set_page_config(page_title=\"Modified Dataset Overview\", page_icon=\"📊\")\n\n# Page title and description\nst.markdown(\"# Modified Diabetes Prediction Dataset Overview\")\nst.write(\n    \"\"\"\n    This page provides details about the **Modified Diabetes Prediction Dataset** and highlights the transformations applied to enhance its suitability for analysis and modeling.\n    \n    ### Key Transformations:\n    \n    1. **Removal of Incomplete Examples**:\n       - Any missing or incomplete rows in the dataset were removed to ensure data quality.\n    \n    2. **Balancing the Dataset**:\n       - The dataset initially had an approximate ratio of 10:1 (non-diabetic to diabetic cases). This imbalance was addressed by:\n         - **Downsampling** the majority class by 80%.\n         - **Oversampling** the minority class using the SMOTENC method to synthesize new examples while reducing overfitting risks.\n    \n    3. **Column Removal**:\n       - Features with minimal impact on predicting diabetes (e.g., \"Gender\" and \"Never Smoked\") were excluded.\n    \n    4. **Probability-Based Target**:\n       - The ~diabetes~ target column was converted from binary labels (~0~ or ~1~) to a probability, influenced by key factors like **age**. The probabilities are random but biased toward attributes with higher predictive power.\n    \"\"\"\n)\n\n@st.cache_data\ndef load_modified_dataset():\n    return pd.read_csv('Datasets/modified_dataset.csv')\n\n# Load the modified dataset\nmodified_df = load_modified_dataset()\n\n# Display the modified dataset\nst.markdown(\"## Modified Dataset Sample\")\nst.write(\"Here is a sample of the **Modified Diabetes Prediction Dataset**:\")\nst.write(modified_df.head())\n\nst.markdown(\"### Modified Dataset Summary\")\nst.write(\"Below is the statistical summary of the modified dataset:\")\nst.write(modified_df.describe())\n\n# Highlight Differences\nst.markdown(\"## Key Characteristics of the Modified Dataset\")\nst.write(\n    \"\"\"\n    - **Balanced Dataset**:\n      - The dataset is more balanced compared to its original version, addressing the class imbalance issue.\n    - **Cleaned Data**:\n      - All missing or incomplete rows have been removed for better data quality.\n    - **Target Variable Transformation**:\n      - The ~diabetes~ column represents probabilities instead of binary labels.\n    - **Feature Selection**:\n      - Non-informative features like \"Gender\" and \"Never Smoked\" have been excluded.\n    \"\"\"\n)\n"
    },
    "Datasets": {
        "modified_dataset.csv": "age,bmi,average_blood_glucose_level,current_blood_glucose_level,hypertension_1,heart_disease_1,smoking_history_former,diabetes\n0.125,0.0800375542776669,0.0909090909090909,0.3409090909090908,0.0,0.0,0.0,0.18977917098864222\n0.0375,0.2031451707546063,0.0,0.2090909090909091,0.0,0.0,0.0,0.27634007725108634\n0.525,0.1722802487970895,0.2727272727272728,0.2727272727272727,0.0,0.0,0.0,0.342445747212608\n0.875,0.2031451707546063,0.1818181818181818,0.359090909090909,0.0,0.0,0.0,0.3560425491721467\n0.25,0.0997535500528107,0.2363636363636363,0.0,0.0,0.0,0.0,0.12342716537177671\n0.7125,0.2641708719633847,0.5454545454545455,0.3636363636363636,0.0,0.0,0.0,0.33710126027809934\n0.7125,0.1215819739467199,0.2363636363636363,0.0,0.0,0.0,0.0,0.15445584449571115\n0.6375000000000001,0.4322262645229434,0.4909090909090911,0.0227272727272727,0.0,1.0,0.0,0.6261577547868484\n0.625,0.2031451707546063,0.5636363636363636,0.2090909090909091,0.0,0.0,0.0,0.3778974910450176\n...\n0.9875,0.1723976059147987,0.4727272727272728,0.818181818181818,0.0,0.0,0.0,0.3922278955631666\n0.8875000000000001,0.2124163830536322,0.9090909090909092,0.818181818181818,0.0,0.0,0.0,0.5648182856796244\n0.7125,0.3005515784532332,0.7090909090909091,0.5454545454545454,0.0,0.0,0.0,0.47113428756879966\n0.75,0.268161013965497,0.4363636363636364,1.0,0.0,0.0,0.0,0.5782660202994371\n0.6125,0.3978406290341509,0.4727272727272728,0.6363636363636364,0.0,0.0,0.0,0.3989498108964879",
        "model.pkl": "...",
        "original_dataset.csv": "age,bmi,average_blood_glucose_level,current_blood_glucose_level,gender_Male,gender_Other,hypertension_1,heart_disease_1,smoking_history_current,smoking_history_ever,smoking_history_former,smoking_history_never,smoking_history_not current,diabetes_1\n1.0,0.1771708683473389,0.5636363636363636,0.2727272727272727,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0\n0.6746746746746747,0.20203081232493,0.5636363636363636,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n0.3493493493493493,0.20203081232493,0.4,0.3545454545454545,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0\n0.4494494494494494,0.1568627450980391,0.2727272727272728,0.3409090909090908,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0\n0.94994994994995,0.1182306255835667,0.2363636363636363,0.3409090909090908,1.0,0.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0\n0.2492492492492492,0.20203081232493,0.5636363636363636,0.0227272727272727,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0\n0.5495495495495495,0.1085434173669467,0.5454545454545455,0.5454545454545454,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0\n0.9874874874874874,0.1616479925303454,0.4,0.0227272727272727,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n0.5245245245245245,0.2757936507936508,0.2363636363636363,0.2954545454545454,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0\n...\n0.4494494494494494,0.1702847805788982,0.2363636363636363,0.2954545454545454,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n0.024024024024024,0.0859010270774976,0.5454545454545455,0.0909090909090908,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n0.8248248248248248,0.2079831932773109,0.4,0.3409090909090908,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0\n0.2992992992992993,0.2965686274509804,0.0909090909090909,0.0909090909090908,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0\n0.7122122122122122,0.1449579831932773,0.5636363636363636,0.0454545454545454,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0"
    },
    "rasa_backend": {
        "config.yml": "version: \"3.1\"\n\n# Language configuration\nlanguage: en\n\n# NLU pipeline configuration (How the assistant understands the user's input)\npipeline:\n- name: WhitespaceTokenizer\n- name: RegexFeaturizer\n- name: LexicalSyntacticFeaturizer\n- name: CountVectorsFeaturizer\n- name: DIETClassifier\n  epochs: 100\n  constrain_similarities: true\n  intent_classification: true\n  entity_recognition: true\n    # Explicitly specify the user features\n  user_features:\n  - intent\n  - entities\n- name: EntitySynonymMapper\n- name: ResponseSelector\n  epochs: 100\n  constrain_similarities: true\n- name: FallbackClassifier\n  threshold: 0.3\n  ambiguity_threshold: 0.1\n\n\n# Policies configuration (How the assistant decides what actions to take based on user input and conversation history)\n# Configuration for Rasa Core policies\npolicies:\n- name: MemoizationPolicy\n- name: RulePolicy    # Add RulePolicy\n  core_fallback_threshold: 0.3\n  core_fallback_action_name: \"action_default_fallback\"\n  enable_fallback_intents: true\n- name: TEDPolicy\n  max_history: 5\n  epochs: 100\n  constrain_similarities: true\n  user_features:\n  - intent\n  - entities\n  fallback_action_name: \"action_repeat_message\"  # Action when fallback occurs\nassistant_id: 20241207-132732-medium-flush\n",
        "endpoints.yml": "# This file contains the different endpoints your bot can use.\n\n# Server where the models are pulled from.\n# https://rasa.com/docs/rasa/model-storage#fetching-models-from-a-server\n\n#models:\n#  url: http://my-server.com/models/default_core@latest\n#  wait_time_between_pulls:  10   # [optional](default: 100)\n\n# Server which runs your custom actions.\n# https://rasa.com/docs/rasa/custom-actions\n\n#action_endpoint:\n#  url: \"http://localhost:5055/webhook\"\n\n# Tracker store which is used to store the conversations.\n# By default the conversations are stored in memory.\n# https://rasa.com/docs/rasa/tracker-stores\n\n#tracker_store:\n#    type: redis\n#    url: <host of the redis instance, e.g. localhost>\n#    port: <port of your redis instance, usually 6379>\n#    db: <number of your database within redis, e.g. 0>\n#    password: <password used for authentication>\n#    use_ssl: <whether or not the communication is encrypted, default false>\n\n#tracker_store:\n#    type: mongod\n#    url: <url to your mongo instance, e.g. mongodb://localhost:27017>\n#    db: <name of the db within your mongo instance, e.g. rasa>\n#    username: <username used for authentication>\n#    password: <password used for authentication>\n\n# Event broker which all conversation events should be streamed to.\n# https://rasa.com/docs/rasa/event-brokers\n\n#event_broker:\n#  url: localhost\n#  username: username\n#  password: password\n#  queue: queue\n",
        "credentials.yml": "# This file contains the credentials for the voice & chat platforms\n# which your bot is using.\n# https://rasa.com/docs/rasa/messaging-and-voice-channels\n\nrest:\n#  # you don't need to provide anything here - this channel doesn't\n#  # require any credentials\n\n\n#facebook:\n#  verify: \"<verify>\"\n#  secret: \"<your secret>\"\n#  page-access-token: \"<your page access token>\"\n\n#slack:\n#  slack_token: \"<your slack token>\"\n#  slack_channel: \"<the slack channel>\"\n#  slack_signing_secret: \"<your slack signing secret>\"\n\n#socketio:\n#  user_message_evt: <event name for user message>\n#  bot_message_evt: <event name for bot messages>\n#  session_persistence: <true/false>\n\n#mattermost:\n#  url: \"https://<mattermost instance>/api/v4\"\n#  token: \"<bot token>\"\n#  webhook_url: \"<callback URL>\"\n\n# This entry is needed if you are using Rasa Enterprise. The entry represents credentials\n# for the Rasa Enterprise \"channel\", i.e. Talk to your bot and Share with guest testers.\nrasa:\n  url: \"http://localhost:5002/api\"\n",
        "domain.yml": "version: \"3.1\"\n\nintents:\n  - goodbye\n  - bot_challenge\n  - provide_average_glucose_level\n  - provide_hypertension_status\n  - provide_smoking_history\n  - provide_heart_disease_status\n  - provide_age\n  - provide_bmi\n  - provide_current_glucose_level\n  - ask_for_diabetes_check\n  - ask_for_tips\n  - greet\n\nentities:\n  - age\n  - hypertension\n  - heart_disease\n  - bmi\n  - average_glucose\n  - current_glucose\n  - smoking_history\n\n\nresponses:\n\n  utter_greet:\n    - text: \"Hello! How can I assist you today?\"\n\n  utter_goodbye:\n    - text: \"Goodbye! Have a nice day.\"\n  \n  utter_iamabot:\n    - text: \"I am DiaPredictor, a diabetes prediction assistant.\"\n\n  utter_hypertension:\n    - text: \"Do you have hypertension? Please respond with Yes or No.\"\n\n  utter_heart_disease:\n    - text: \"Do you have heart disease? Please respond with Yes or No.\"\n  \n  utter_average_glucose_level:\n    - text: \"What is your average glucose level?\"\n\n  utter_current_glucose_level:\n    - text: \"What is your current glucose level?\"\n  \n  utter_smoking_history:\n    - text: \"What’s your smoking history: Never, Former, or Current? Please respond with one of the provided answers.\"\n  \n  utter_show_result:\n    - text: \"Here is your diabetes risk result.\"\n  \n  utter_age:\n    - text: \"Okay, let's do that! How old are you?\"\n  \n  utter_bmi:\n    - text: \"What is your BMI?\"\n\n  utter_hello:\n    - text: \"Hello. How can I help you today?\"\n\nactions:\n  - action_save_user_data\n  - action_predict_diabetes\n  - action_provide_tips\n\nslots:\n  age:\n    type: float\n    mappings:\n      - type: from_entity\n        entity: age\n\n  hypertension:\n    type: categorical\n    values:\n      - yes\n      - no\n    mappings:\n      - type: from_entity\n        entity: hypertension\n\n  heart_disease:\n    type: categorical\n    values:\n      - yes\n      - no\n    mappings:\n      - type: from_entity\n        entity: heart_disease\n\n  bmi:\n    type: float\n    mappings:\n      - type: from_entity\n        entity: bmi\n\n  average_glucose:\n    type: float\n    mappings:\n      - type: from_entity\n        entity: average_glucose\n\n  current_glucose:\n    type: float\n    mappings:\n      - type: from_entity\n        entity: current_glucose\n\n  smoking_history:\n    type: categorical\n    values:\n      - never\n      - former\n      - current\n    mappings:\n      - type: from_entity\n        entity: smoking_history\n\n",
        "models": {},
        "actions": {
            "__init__.py": "",
            "actions.py": "import random\nfrom typing import Any, Text, Dict, List\nfrom rasa_sdk import Action, Tracker\nfrom rasa_sdk.executor import CollectingDispatcher\nfrom rasa_sdk.events import SlotSet\nimport joblib\nfrom Additional_Scripts import normalizing_inputs\n\nclass ActionProvideTips(Action):\n    def name(self) -> str:\n        return \"action_provide_tips\"\n    \n    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: dict) -> list:\n        # Retrieve the slots\n        age = tracker.get_slot(\"age\")\n        bmi = tracker.get_slot(\"bmi\")\n        smoking_history = tracker.get_slot(\"smoking_history\")\n        hypertension = tracker.get_slot(\"hypertension\")\n        heart_disease = tracker.get_slot(\"heart_disease\")\n        current_glucose = tracker.get_slot(\"current_glucose\")\n        \n        tips = []\n\n        # Randomize the glucose level tips\n        if current_glucose > 180:\n            tips.append(random.choice([\n                \"Your glucose levels are high. Consider reducing sugar intake, focusing on low-carb foods, and increasing fiber to help stabilize your levels. It’s essential to consult with your doctor about a management plan.\",\n                \"With glucose levels above 180, it’s crucial to cut back on sugary foods and drinks. Focus on whole grains and leafy vegetables. Regular exercise can help stabilize your levels as well.\"\n            ]))\n\n        elif current_glucose > 140:\n            tips.append(random.choice([\n                \"Your glucose levels are elevated. To help manage them, avoid sugary snacks and drinks, and consider regular physical activity such as walking or light jogging. Monitoring your glucose levels closely will help track progress.\",\n                \"Elevated glucose levels can be managed with a balanced diet and regular exercise. Aim to limit high-sugar foods and increase fiber intake to stabilize your levels.\"\n            ]))\n\n        # Randomize BMI tips\n        if bmi >= 30:\n            tips.append(random.choice([\n                \"A BMI over 30 indicates a higher risk for complications. Incorporating regular physical activity, such as daily walks, and focusing on a balanced diet with fruits, vegetables, and lean proteins can help reduce your BMI. Small changes over time can make a big difference.\",\n                \"With a BMI over 30, it’s important to start incorporating small changes. Begin by walking 30 minutes a day and incorporating more plant-based foods into your diet to improve your weight and health.\"\n            ]))\n\n        # Randomize heart disease tips\n        if heart_disease:\n            tips.append(random.choice([\n                \"Given your history of heart disease, it’s important to follow a heart-healthy diet that’s rich in omega-3 fatty acids, whole grains, and low in saturated fats. Regular exercise and managing stress levels will also contribute to better heart health.\",\n                \"Since you have heart disease, focus on a diet rich in fruits, vegetables, and whole grains while limiting unhealthy fats. Regular cardiovascular exercise will also help support heart health.\"\n            ]))\n\n        # Randomize hypertension tips\n        if hypertension:\n            tips.append(random.choice([\n                \"Managing hypertension is critical. Focus on reducing salt intake, avoid processed foods, and engage in stress-relieving activities like yoga or meditation. Keeping your blood pressure under control will help reduce the strain on your heart.\",\n                \"To manage hypertension, reduce salt intake and avoid high-sodium foods. Regular exercise like walking and relaxing activities like meditation will help keep your blood pressure in check.\"\n            ]))\n\n        # Randomize smoking history tips\n        if smoking_history == \"Current\":\n            tips.append(random.choice([\n                \"Smoking has a negative impact on both your heart and lung health. Consider seeking support to quit smoking, whether through counseling, nicotine replacement therapy, or a support group. Quitting smoking will improve your circulation and overall well-being.\",\n                \"Since you're a current smoker, consider seeking help to quit. Smoking cessation will improve circulation, reduce your risk of heart disease, and benefit your overall health.\"\n            ]))\n\n        # Send back all of the tips based on the user information #\n        dispatcher.utter_message(\"\\n\".join(tips))\n\n        return []\n    \nclass ActionPredictDiabetes(Action):\n    def name(self) -> str:\n        return \"action_predict_diabetes\"\n    \n    # Load the model\n    def __init__(self):\n        self.model = joblib.load(\"Datasets/model.pkl\")\n    \n    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: dict) -> list:\n        # Retrieve the slots\n        age = tracker.get_slot(\"age\")\n        bmi = tracker.get_slot(\"bmi\")\n        smoking_history = tracker.get_slot(\"smoking_history\")\n        hypertension = tracker.get_slot(\"hypertension\")\n        heart_disease = tracker.get_slot(\"heart_disease\")\n        current_glucose = tracker.get_slot(\"current_glucose\")\n        average_glucose = tracker.get_slot(\"average_glucose\")\n\n        # Normalizes input values\n        inputs = [[age, bmi, average_glucose, current_glucose]]\n\n        # Prepare user input as a feature vector\n        features = normalizing_inputs.normalize_inputs(inputs, smoking_history, hypertension, heart_disease)\n\n        prediction = self.model.predict(features)[0]  # Predict using the model\n\n        if prediction < 0.3:\n            dispatcher.utter_message(\"You are unlikely to have diabetes. Nonetheless, it’s always good to keep track of your health.\")\n        elif prediction < 0.7:\n            dispatcher.utter_message(\"You have a moderate risk of diabetes. Consider adopting healthier lifestyle choices and monitor your health regularly.\")\n        else:\n            dispatcher.utter_message(\"You have a high risk of diabetes. I strongly recommend consulting a doctor for further testing.\")\n\nclass ActionProvideMissingData(Action):\n    def name(self) -> str:\n        return \"action_provide_missing_data\"\n\n    def run(self, dispatcher, tracker, domain):\n        missing_data = []\n\n        # Check for each slot, and if missing, add it to the list\n        if not tracker.get_slot(\"age\"):\n            missing_data.append(\"age\")\n        if not tracker.get_slot(\"hypertension\"):\n            missing_data.append(\"hypertension\")\n        if not tracker.get_slot(\"heart_disease\"):\n            missing_data.append(\"heart_disease\")\n        if not tracker.get_slot(\"bmi\"):\n            missing_data.append(\"bmi\")\n        if not tracker.get_slot(\"average_glucose\"):\n            missing_data.append(\"average_glucose\")\n        if not tracker.get_slot(\"current_glucose\"):\n            missing_data.append(\"current_glucose\")\n        if not tracker.get_slot(\"smoking_history\"):\n            missing_data.append(\"smoking_history\")\n\n        if missing_data:\n            # If any data is missing, prompt the user for each one\n            message = \"I need the following information to proceed: \"\n            message += \", \".join(missing_data)\n            dispatcher.utter_message(message)\n\nclass ActionRepeatMessage(Action):\n    def name(self):\n        return \"action_repeat_message\"\n\n    def run(self, dispatcher, tracker, domain):\n        dispatcher.utter_message(text=\"Please respond only with one of the provided possible answers.\")\n        return []\n\n\n",
            "__pycache__": {
                "__init__.cpython-310.pyc": "...",
                "actions.cpython-310.pyc": "..."
            }
        },
        "data": {
            "rules.yml": "version: \"3.1\"\n\nrules:\n- rule: Say goodbye anytime the user says goodbye\n  steps:\n  - intent: goodbye\n  - action: utter_goodbye\n\n- rule: Say 'I am DiaPredictor, a diabetes prediction assistant.' anytime the user challenges\n  steps:\n  - intent: bot_challenge\n  - action: utter_iamabot\n\n- rule: Collect user data and confirm age\n  steps:\n  - action: utter_age\n  - intent: provide_age\n\n- rule: Collect user data and confirm bmi\n  steps:\n  - action: utter_bmi\n  - intent: provide_bmi\n\n- rule: Collect user data and confirm hypertension\n  steps:\n  - action: utter_hypertension\n  - intent: provide_hypertension_status\n\n- rule: Collect user data and confirm heart disease\n  steps:\n  - action: utter_heart_disease\n  - intent: provide_heart_disease_status\n\n- rule: Collect user data and confirm current glucose level\n  steps:\n  - action: utter_current_glucose_level\n  - intent: provide_current_glucose_level\n  \n- rule: Collect user data and confirm average glucose level\n  steps:\n  - action: utter_average_glucose_level\n  - intent: provide_average_glucose_level\n\n- rule: Collect smoking history\n  steps:\n  - action: utter_smoking_history\n  - intent: provide_smoking_history\n\n- rule: Greet user\n  steps:\n  - intent: greet\n  - action: utter_greet\n\n- rule: Give back the results of the diabetes prediction\n  steps:\n  - action: action_predict_diabetes\n  - action: utter_show_result",
            "stories.yml": "version: \"3.1\"\n\nstories:\n# Use Case 1\n  - story: user starts diabetes check\n    steps:\n      - action: utter_hello\n      - intent: ask_for_diabetes_check\n      - action: utter_age\n      - intent: provide_age\n        entities:\n          - age: \"my age is 45\"\n      - checkpoint: got_age\n\n  - story: get hypertension\n    steps:\n      - checkpoint: got_age\n      - action: utter_hypertension\n      - intent: provide_hypertension_status\n        entities:\n          - hypertension: \"No, i dont have hypertension\"\n      - checkpoint: got_hypertension\n\n  - story: get heart disease\n    steps:\n      - checkpoint: got_hypertension\n      - action: utter_heart_disease\n      - intent: provide_heart_disease_status\n        entities:\n          - heart_disease: \"No, i dont have heart disease\"\n      - checkpoint: got_heart_disease\n\n  - story: provide bmi\n    steps:\n      - checkpoint: got_heart_disease\n      - action: utter_bmi\n      - intent: provide_bmi\n        entities:\n          - bmi: \"28.5 bmi\"\n      - checkpoint: got_bmi\n\n  - story: provide average glucose\n    steps:\n    - checkpoint: got_bmi\n    - action: utter_average_glucose_level\n    - intent: provide_average_glucose_level\n      entities:\n        - average_glucose: \"120 mg/dL average glucose\"\n    - checkpoint: got_average_glucose\n\n  - story: provide current glucose\n    steps:\n    - checkpoint: got_average_glucose\n    - action: utter_current_glucose_level\n    - intent: provide_current_glucose_level\n      entities:\n        - current_glucose: \"140 mg/dL current glucose\"\n    - checkpoint: got_current_glucose\n\n  - story: smoking history and save data\n    steps:\n    - checkpoint: got_current_glucose\n    - action: utter_smoking_history\n    - intent: provide_smoking_history\n      entities:\n        - smoking_history: \"Former\"\n    - action: action_save_user_data\n    - checkpoint: got_smoking_history\n\n  - story: get diabetes prediction\n    steps:\n    - checkpoint: got_smoking_history\n    - action: action_predict_diabetes\n    - action: utter_show_result\n    - intent: goodbye\n    - action: utter_goodbye\n\n# Use Case 2\n  - story: user starts diabetes tips\n    steps:\n      - action: utter_hello\n      - intent: ask_for_tips\n      - action: utter_age\n      - intent: provide_age\n        entities:\n          - age: \"45 years old\"\n      - checkpoint: got_age_tips\n\n  - story: get hypertension\n    steps:\n      - checkpoint: got_age_tips\n      - action: utter_hypertension\n      - intent: provide_hypertension_status\n        entities:\n          - hypertension: \"No, i dont have hypertension\"\n      - checkpoint: got_hypertension_tips\n\n  - story: get heart disease\n    steps:\n      - checkpoint: got_hypertension_tips\n      - action: utter_heart_disease\n      - intent: provide_heart_disease_status\n        entities:\n          - heart_disease: \"No, i dont have heart disease\"\n      - checkpoint: got_heart_disease_tips\n\n  - story: provide bmi\n    steps:\n      - checkpoint: got_heart_disease_tips\n      - action: utter_bmi\n      - intent: provide_bmi\n        entities:\n          - bmi: \"28.5 bmi\"\n      - checkpoint: got_bmi_tips\n\n  - story: provide average glucose\n    steps:\n    - checkpoint: got_bmi_tips\n    - action: utter_average_glucose_level\n    - intent: provide_average_glucose_level\n      entities:\n        - average_glucose: \"120 mg/dL average glucose\"\n    - checkpoint: got_average_glucose_tips\n\n  - story: provide current glucose\n    steps:\n    - checkpoint: got_average_glucose_tips\n    - action: utter_current_glucose_level\n    - intent: provide_current_glucose_level\n      entities:\n        - current_glucose: \"140 mg/dL current glucose\"\n    - checkpoint: got_current_glucose_tips\n\n  - story: smoking history and results\n    steps:\n    - checkpoint: got_current_glucose_tips\n    - action: utter_smoking_history\n    - intent: provide_smoking_history\n      entities:\n        - smoking_history: \"Former\"\n    - action: action_save_user_data\n    - checkpoint: got_smoking_history_tips\n\n  - story: get tips based off of user entries\n    steps:\n    - checkpoint: got_smoking_history_tips\n    - action: action_provide_tips\n    - intent: goodbye\n    - action: utter_goodbye\n\n  - story: greet the user\n    steps:\n    - intent: greet\n    - action: utter_greet\n",
            "nlu.yml": "version: \"3.1\"\n\nnlu:\n  - intent: goodbye\n    examples: |\n      - Goodbye\n      - See you later\n      - Bye\n      - Take care\n      - Farewell\n      - See you soon\n      - Have a great day\n      - It was nice talking to you\n      - bye\n      - see ya\n      - cya\n      - hav a gud day\n      - later\n      - it was nice talk to you\n\n  - intent: bot_challenge\n    examples: |\n      - Are you a bot?\n      - Are you human?\n      - Are you real?\n      - Who are you?\n      - What is this system?\n      - Are you a robot?\n      - Can I talk to a real person?\n      - are you bot\n      - you real?\n      - who r u\n      - this robot?\n      - wat is dis\n      - can i chat w a human?\n\n  - intent: greet\n    examples: |\n      - Hello\n      - Hi\n      - Hey there\n      - Good morning\n      - Hiya\n      - Hey\n      - hello\n      - hi\n\n\n  - intent: ask_for_diabetes_check\n    examples: |\n      - Hi, can you check if I might have diabetes?\n      - Can you help me find out if I might have diabetes?\n      - Can you check if I have a high chance of having diabetes?\n      - I want to know if I have diabetes.\n      - Can you tell me if I am at risk for diabetes?\n      - Can you predict if I have diabetes?\n      - Do I have a chance of having diabetes?\n      - How can I know if I have diabetes?\n      - hi can u check if I hav diabetes\n      - help me kno if hav diabetes\n      - check if diabetes possible for me\n      - do i hav diabetes\n      - pls tel me my diabetes risk\n      - check my diabetes\n\n  - intent: provide_age\n    examples: |\n      - I'm [45](age).\n      - I am [24](age).\n      - My age is [50](age).\n      - I’m [38](age) years old.\n      - I’m [29](age).\n      - I’ll be [40](age) soon.\n      - I’m [33](age) years old.\n      - i [45](age)\n      - im [24](age)\n      - i am [33](age)\n      - age is [38](age)\n\n  - intent: provide_hypertension_status\n    examples: |\n      - [No](hypertension), I don’t have hypertension.\n      - [Yes](hypertension), I have hypertension.\n      - [Yes](hypertension), I have high blood pressure.\n      - [no] i dont have it\n      - [yes](hypertension), i have high bp\n\n  - intent: provide_heart_disease_status\n    examples: |\n      - [No](heart_disease), I don’t have.\n      - [Yes](heart_disease), I have heart disease.\n      - [Yes](heart_disease), I’ve been diagnosed with heart disease.\n      - [No](heart_disease), my heart is healthy.\n      - [no](heart_disease) i dont hav heart prob\n      - [yes](heart_disease) hav heart issue\n      - [no](heart_disease) heart problem\n\n  - intent: provide_bmi\n    examples: |\n      - It's [28.5](bmi).\n      - My BMI is [24](bmi).\n      - It’s [32](bmi).\n      - I have a BMI of [27](bmi).\n      - My BMI is [30](bmi).\n      - I’m BMI [23](bmi).\n      - My BMI is considered normal.\n      - I have a high BMI of [35](bmi).\n      - bmi [27](bmi)\n      - my bmi [23](bmi)\n      - it is [30.5](bmi)\n\n  - intent: provide_average_glucose_level\n    examples: |\n      - Around [120](average_glucose) mg/dL.\n      - [100](average_glucose) mg/dL.\n      - [145](average_glucose) mg/dL.\n      - My average glucose is [130](average_glucose) mg/dL.\n      - I usually have a glucose level of [115](average_glucose) mg/dL.\n      - My average glucose is [110](average_glucose) mg/dL.\n      - It’s typically [125](average_glucose) mg/dL.\n      - My glucose level averages at [140](average_glucose) mg/dL.\n      - glucose [130](average_glucose)\n      - avg glucose [110](average_glucose)\n      - glucose level is normal\n      - avg sugar [120](average_glucose) mg\n      - glucose is [125](average_glucose)\n      - [145](average_glucose) glucose\n\n  - intent: provide_current_glucose_level\n    examples: |\n      - It’s [140](current_glucose) mg/dL.\n      - [110](current_glucose) mg/dL.\n      - [150](current_glucose) mg/dL.\n      - My current glucose is [130](current_glucose) mg/dL.\n      - I just measured my glucose and it’s [160](current_glucose) mg/dL.\n      - It was [145](current_glucose) mg/dL when I checked.\n      - My current blood sugar level is [120](current_glucose) mg/dL.\n      - My glucose is currently at [135](current_glucose) mg/dL.\n      - current glucose [140](current_glucose)\n      - my glucose now [150](current_glucose)\n      - sugar is [135](current_glucose)\n      - it [145](current_glucose)\n      - glucose is [120](current_glucose) now\n      - [140](current_glucose) sugar level\n\n  - intent: provide_smoking_history\n    examples: |\n      - [Former](smoking_history).\n      - [Never](smoking_history).\n      - [Current](smoking_history).\n      - [former](smoking_history) smoker\n      - [current](smoking_history) smoker\n      - [never](smoking_history) smoked\n      - [Former](smoking_history) smoker.\n      - [Current](smoking_history) smoker.\n      - [Never](smoking_history) smoked.\n\n  - intent: ask_for_tips\n    examples: |\n      - Can you give me some tips to manage my diabetes?\n      - I need tips to manage my diabetes.\n      - Do you have any advice for me?\n      - How could I manage my diabetes?\n      - How do I take better care of my diabetes?\n      - Could you provide advice on managing diabetes?\n      - What are some effective ways to manage diabetes?\n      - What should I do to keep my diabetes in check?\n      - Are there any tricks to manage diabetes effectively?\n      - What lifestyle changes can help with diabetes?\n      - Tips for managing diabetes?\n\n\nentities:\n  - age\n  - hypertension\n  - heart_disease\n  - bmi\n  - average_glucose\n  - current_glucose\n  - smoking_history\n\nslots:\n  age:\n    type: number\n  hypertension:\n    type: binary\n  heart_disease:\n    type: binary\n  bmi:\n    type: number\n  average_glucose:\n    type: number\n  current_glucose:\n    type: number\n  smoking_history:\n    type: unfeaturized\n"
        },
        "tests": {
            "test_stories.yml": "#### This file contains tests to evaluate that your bot behaves as expected.\n#### If you want to learn more, please see the docs: https://rasa.com/docs/rasa/testing-your-assistant\n\nstories:\n- story: happy path 1\n  steps:\n  - user: |\n      hello there!\n    intent: greet\n  - action: utter_greet\n  - user: |\n      amazing\n    intent: mood_great\n  - action: utter_happy\n\n- story: happy path 2\n  steps:\n  - user: |\n      hello there!\n    intent: greet\n  - action: utter_greet\n  - user: |\n      amazing\n    intent: mood_great\n  - action: utter_happy\n  - user: |\n      bye-bye!\n    intent: goodbye\n  - action: utter_goodbye\n\n- story: sad path 1\n  steps:\n  - user: |\n      hello\n    intent: greet\n  - action: utter_greet\n  - user: |\n      not good\n    intent: mood_unhappy\n  - action: utter_cheer_up\n  - action: utter_did_that_help\n  - user: |\n      yes\n    intent: affirm\n  - action: utter_happy\n\n- story: sad path 2\n  steps:\n  - user: |\n      hello\n    intent: greet\n  - action: utter_greet\n  - user: |\n      not good\n    intent: mood_unhappy\n  - action: utter_cheer_up\n  - action: utter_did_that_help\n  - user: |\n      not really\n    intent: deny\n  - action: utter_goodbye\n\n- story: sad path 3\n  steps:\n  - user: |\n      hi\n    intent: greet\n  - action: utter_greet\n  - user: |\n      very terrible\n    intent: mood_unhappy\n  - action: utter_cheer_up\n  - action: utter_did_that_help\n  - user: |\n      no\n    intent: deny\n  - action: utter_goodbye\n\n- story: say goodbye\n  steps:\n  - user: |\n      bye-bye!\n    intent: goodbye\n  - action: utter_goodbye\n\n- story: bot challenge\n  steps:\n  - user: |\n      are you a bot?\n    intent: bot_challenge\n  - action: utter_iamabot\n"
        }
    }
}