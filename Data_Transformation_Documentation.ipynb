{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis before Data Transformation\n",
    "Data visualization has provided the following information about the unprocessed dataset:\n",
    "1. When analysis of correlation between age and diabetes is made, there a small fall of cases in between the middle 60s and 70s. Afterwards, an abrupt jump is observed at around 80.\n",
    "\n",
    "2. The cases of diabetes in males and females differs very little.\n",
    "\n",
    "3. The mean and median do not differ majorly, leading to an almost symmetrical dataset. \n",
    "\n",
    "4. The quartiles show an expected variation in attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For term documentation, please visit the Wiki on GitLab: Statistical Term Documentation #\n",
    "\n",
    "df = pd.read_csv('smotted_dataset.csv')\n",
    "\n",
    "#Show ratio through chart\n",
    "#sns.countplot(x='diabetes', data=df)\n",
    "\n",
    "# Age Distribution\n",
    "sns.histplot(data=df, x='age', hue='diabetes', multiple='stack')\n",
    "\n",
    "# Blood Glucose Levels Distribution\n",
    "#sns.histplot(data=df, x='current_blood_glucose_level', hue='diabetes', multiple='stack')\n",
    "\n",
    "#HbA1c_level\n",
    "#sns.histplot(data=df, x='average_blood_glucose_level', hue='diabetes', multiple='stack')\n",
    "\n",
    "# Weight Distribution\n",
    "# Plot KDE for BMI with diabetes status\n",
    "#sns.kdeplot(data=df, x='bmi', hue='diabetes', fill=True)\n",
    "\n",
    "numerical_df = df.select_dtypes(include=['float64', 'int64']).drop(columns=['hypertension', 'heart_disease', 'diabetes'])\n",
    "# Mean and Median\n",
    "print(\"Median:\", numerical_df.median(), \"\\n\")\n",
    "print(\"Mean:\", numerical_df.mean(), \"\\n\")\n",
    "\n",
    "# Standard Deviation\n",
    "print(\"Standard Deviation:\", numerical_df.std())\n",
    "\n",
    "# The values at the quartile divisions\n",
    "print(numerical_df.quantile(q=[0.25, 0.5, 0.75], axis=0, numeric_only=True))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removal of Incomplete Examples in Dataset\n",
    "With the utilization of Pandas, any incomplete examples present in our dataset were removed. Afterwards, we have analyzed the data to ensure that all of our labels are direct labels and not proxy labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('cleaned_dataset.csv')\n",
    "df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.to_csv('cleaned_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Balancing Dataset\n",
    "Furthermore, the next step was reaching a dataset which was as balanced as possible. Initially, the dataset had a ratio of approximately 10:1 (10 non-diabetic individuals for a single diabetic patient).\n",
    "\n",
    "The following steps were performed:\n",
    "1. The majority class was downsampled by a factor of 5 (20%). Although the downsampling could have been up to a factor of 10, this would lead to extreme data loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('cleaned_dataset.csv')\n",
    "\n",
    "X = df.drop('diabetes', axis=1)\n",
    "y = df['diabetes']\n",
    "\n",
    "# Undersampling the majority class\n",
    "# Sampling Strategy allows to remove a certain percentage of the majority in this case. Currently, we undersample by a factor of 5.#\n",
    "# Ratio is 5:1 for non-diabetics \n",
    "rus = RandomUnderSampler(random_state=42, sampling_strategy = 0.2)\n",
    "X_res, y_res = rus.fit_resample(X, y)\n",
    "\n",
    "# Ratio after undersampling\n",
    "ratio = 42410 / 8482\n",
    "#print(X_res.value_counts(), y_res.value_counts(), f\"Ratio: {ratio}\")\n",
    "df_resampled = pd.concat([X_res, y_res], axis=1)\n",
    "df_resampled['age'] = df_resampled['age'].astype(int)\n",
    "df_resampled.to_csv('downsampled_dataset.csv', index=False) # Creates a different file with removed majority #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The minority class was oversampled utilizing the Synthetic Minority Over-sampling Technique for Nominal and Continuous. (SMOTENC) method. SMOTENC is required, as the dataset contains both categorical and numerical data. Although overfitting is still a problem to be considered, as new data isn't created but fabricated from pre-existing data, it reduces the chances of overfitting in comparison to Random Oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "import pandas as pd\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv('downsampled_dataset.csv')\n",
    "X = df.drop('diabetes', axis=1)\n",
    "y = df['diabetes']\n",
    "\n",
    "# Convert categorical variables to numeric codes before SMOTE\n",
    "valid_smoking_history = ['never', 'former', 'current', 'No Info']\n",
    "X['smoking_history'] = pd.Categorical(X['smoking_history'], \n",
    "                                    categories=valid_smoking_history,\n",
    "                                    ordered=False)\n",
    "X['smoking_history'] = X['smoking_history'].cat.codes\n",
    "\n",
    "# Get the indices of categorical features\n",
    "categorical_features_indices = [X.columns.get_loc(col) for col in ['gender', 'smoking_history']]\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTENC(random_state=42, \n",
    "                sampling_strategy=0.5, \n",
    "                k_neighbors=5, \n",
    "                categorical_features=categorical_features_indices)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# Convert smoking_history back to categories\n",
    "X_res['smoking_history'] = pd.Categorical.from_codes(\n",
    "    X_res['smoking_history'].astype('int'),\n",
    "    categories=valid_smoking_history\n",
    ")\n",
    "\n",
    "# Round numerical columns to match desired format\n",
    "# Assuming the columns are in this order: age, hypertension, heart_disease, bmi, HbA1c_level, blood_glucose_level\n",
    "X_res['age'] = X_res['age'].round().astype(int)\n",
    "X_res['bmi'] = X_res['bmi'].round(2)\n",
    "X_res['average_blood_glucose_level'] = X_res['average_blood_glucose_level'].round(1)\n",
    "X_res['current_blood_glucose_level'] = X_res['current_blood_glucose_level'].round().astype(int)\n",
    "# hypertension and heart_disease should already be 0 or 1\n",
    "\n",
    "# Create the resampled dataset\n",
    "df_resampled = pd.concat([X_res, y_res], axis=1)\n",
    "\n",
    "# Save with correct formatting\n",
    "df_resampled.to_csv('smotted_dataset.csv', index=False, float_format='%.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Dataset\n",
    "The dataset was split into a Training Set, Validation Set and Test Set:\n",
    "- Training Set: 70%\n",
    "- Validation Set: 15%\n",
    "- Test Set: 15%\n",
    "\n",
    "The initial splitting of the dataset leads to a 1:3 imbalance for diabetics. Variations will be tested on the models being trained and documented in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('smotted_dataset.csv')\n",
    "X = df.drop('diabetes', axis=1)\n",
    "y = df['diabetes']\n",
    "\n",
    "# First split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y , \n",
    "                                   random_state=104,  \n",
    "                                   test_size=0.3,  \n",
    "                                   shuffle=True)\n",
    "\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "df_test = pd.concat([X_test, y_test], axis = 1)\n",
    "\n",
    "df_train.to_csv('train_dataset.csv', index = False, float_format='%.2f')\n",
    "\n",
    "# Second split\n",
    "X = df_test.drop('diabetes', axis=1)\n",
    "y = df_test['diabetes']\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X,y , \n",
    "                                            random_state=104,  \n",
    "                                            test_size=0.5,  \n",
    "                                            shuffle=True)\n",
    "\n",
    "df_test = pd.concat([X_test, y_test], axis = 1)\n",
    "df_validation = pd.concat([X_validation, y_validation], axis = 1)\n",
    "\n",
    "df_test.to_csv('test_dataset.csv', index= False, float_format='%.2f')\n",
    "df_validation.to_csv('validation_dataset.csv', index= False, float_format='%.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Categorical Data into Floating Point using Hot-End Encoding\n",
    "As models can only train with floating point values, categorical data (data which is string, or numbers which can not be cateorized as numerical data, such as postal codes) must be transformed into numerical data. As each categorical value of our dataset does not contain more than 4 different categories, we have opted for Hot-End Encoding.\n",
    "\n",
    "Hod-End Encoding will split the categorical data into multiple columns. For example, when the column \"Gender\" is Hot-End Encoded, it will end up having Gender_Female and Gender_Male. 1 will represent the presence, 0 the absence, in order to avoid biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv('Data Transformation/linear_scaled_dataset.csv')\n",
    "\n",
    "# Extract categorical columns from the dataframe\n",
    "categorical_columns = ['gender', 'hypertension', 'heart_disease', 'smoking_history', 'diabetes']\n",
    "\n",
    "# Initialize OneHotEncoder (dropping the first category to avoid redundant columns)\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "# Apply one-hot encoding to the categorical columns\n",
    "one_hot_encoded = encoder.fit_transform(df[categorical_columns])\n",
    "\n",
    "# Create a DataFrame with the one-hot encoded columns\n",
    "one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "# Create a DataFrame for the original numerical columns\n",
    "numerical_columns = ['age', 'bmi', 'average_blood_glucose_level', 'current_blood_glucose_level']\n",
    "numerical_df = df[numerical_columns]\n",
    "\n",
    "# Concatenate the one-hot encoded dataframe with the original numerical dataframe\n",
    "df_encoded = pd.concat([numerical_df, one_hot_df], axis=1)\n",
    "\n",
    "# Save the encoded DataFrame to a CSV file\n",
    "df_encoded.to_csv('cat_to_num.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization\n",
    "Data visualization after the balancing technique SMOTE-NC has been applied shows the following:\n",
    "1. When analysis of correlation between age and diabetes is made, a zig-zag pattern is observed and a sudden jump in registered cases happens at 75-80, to about double the amount of the other highest reigstered number of cases. To combat prediction bias, both will be addressed.\n",
    "\n",
    "2. The cases of diabetes in males and females differs slightly.\n",
    "\n",
    "3. The mean and median still do not differ majorly, although the SMOTE-NC balancing has added some variation. The standard deviation shows the biggest change in the blood glucose levels, which have spiked from 40.90 to 52.55.\n",
    "\n",
    "4. The quartiles show an expected variation in attributes, although has a higher variation in comparison to the original dataset.\n",
    "\n",
    "## Linear Scaling\n",
    "Given that the dataset does not seem to be in a normal distribution, required for Z-Score standardization, nor have a consistent relation of power law, we have opted for linear scaling: the lower and upper values should, in theory, not change over time. Additionally, the dataset contains few to no outliers. \n",
    "\n",
    "The only problem is the fact that the features are not all uniformly distributed across their ranges, are some are more right skewed. Age would be an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = pd.read_csv('smotted_dataset.csv')\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[['age', 'bmi', 'average_blood_glucose_level', 'current_blood_glucose_level']] = scaler.fit_transform(df[['age', 'bmi', 'average_blood_glucose_level', 'current_blood_glucose_level']])\n",
    "\n",
    "df.to_csv('linear_scaled_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
